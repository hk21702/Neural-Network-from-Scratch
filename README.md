# Neural Network from Scratch

Project for Senior Options - 2020

Trying to create a basic neural network from scratch showing all of the different portions without using many libraries.

Utilizes the MNIST database of handwritten digits: http://yann.lecun.com/exdb/mnist/

- [x] 2 hidden layers + input and output layers
- [x] Softmax for output layer normalization
- [x] 5 different activation algorithms:
  -  Swish
  -  E-Swish
  -  Relu
  -  Leaky Relu
  -  Sigmoid

Based heavily on https://mlfromscratch.com/neural-network-tutorial/#/ with modifications mostly to feature other activation algorithms.
